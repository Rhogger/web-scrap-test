# Web Scraping - Linguagens de ProgramaÃ§Ã£o ğŸ•·ï¸ğŸ“Š

Projeto de web scraping para extrair dados sobre linguagens de programaÃ§Ã£o da Wikipedia, com anÃ¡lise e visualizaÃ§Ã£o dos dados coletados.

## ğŸ“– Sobre o Projeto

Este projeto realiza web scraping da [Lista de linguagens de programaÃ§Ã£o da Wikipedia](https://pt.wikipedia.org/wiki/Lista_de_linguagens_de_programa%C3%A7%C3%A3o) para extrair informaÃ§Ãµes sobre linguagens de programaÃ§Ã£o, seus paradigmas, criadores e anos de criaÃ§Ã£o. Os dados sÃ£o processados e organizados para anÃ¡lise posterior.

### ğŸ¯ Objetivos

- Extrair dados estruturados sobre linguagens de programaÃ§Ã£o
- Analisar tendÃªncias e padrÃµes nas linguagens ao longo do tempo
- Visualizar a evoluÃ§Ã£o dos paradigmas de programaÃ§Ã£o
- Criar um dataset limpo e organizado para futuras anÃ¡lises

## âœ¨ Tecnologias Utilizadas

- **Python 3.12** - Linguagem principal
- **Pandas** - ManipulaÃ§Ã£o e anÃ¡lise de dados
- **BeautifulSoup4** - Parsing de HTML para web scraping
- **Requests** - RequisiÃ§Ãµes HTTP
- **Ruff** - Linting e formataÃ§Ã£o de cÃ³digo

### ğŸ“Š Dados ExtraÃ­dos

O projeto coleta as seguintes informaÃ§Ãµes de cada linguagem:

- Nome da linguagem
- Link para a pÃ¡gina da Wikipedia
- Paradigmas de programaÃ§Ã£o (quando disponÃ­vel)
- Ano de criaÃ§Ã£o (quando disponÃ­vel)
- Criadores/desenvolvedores (quando disponÃ­vel)

## ğŸ“‹ PrÃ©-requisitos

- Python 3.12 ou superior
- Git
- Pipenv ou venv (para gerenciamento de dependÃªncias)

## ğŸ”§ InstalaÃ§Ã£o

### 1. Clone o repositÃ³rio

```bash
git clone https://github.com/Rhogger/web-scrap-test.git
cd web-scrap-test
```

### 2. Configure o ambiente virtual

Escolha uma das opÃ§Ãµes abaixo:

#### OpÃ§Ã£o A: Usando Pipenv (Recomendado)

```bash
# Instale o Pipenv (se nÃ£o tiver instalado)
pip install pipenv

# Instale as dependÃªncias
pipenv install

# Ative o ambiente virtual
pipenv shell
```

#### OpÃ§Ã£o B: Usando venv

```bash
# Crie o ambiente virtual
python -m venv venv

# Ative o ambiente virtual
# Linux/Mac:
source venv/bin/activate
# Windows:
# venv\Scripts\activate

# Instale as dependÃªncias
pip install -r requirements.txt
```

## ğŸ“ Estrutura do Projeto

```text
web-scrap-test/
â”œâ”€â”€ backend/                    # Scripts de web scraping e processamento
â”‚   â”œâ”€â”€ src/                   # CÃ³digo fonte do backend
â”‚   â”‚   â”œâ”€â”€ scrape_languages.py   # Script principal de web scraping
â”‚   â”‚   â””â”€â”€ data/                  # Dados extraÃ­dos
â”‚   â”‚       â””â”€â”€ linguagens_programacao_tabela.csv
â”‚   â””â”€â”€ README.md              # DocumentaÃ§Ã£o do backend
â”œâ”€â”€ .vscode/                 # ConfiguraÃ§Ãµes do VS Code
â”œâ”€â”€ .gitattributes          # ConfiguraÃ§Ã£o para diffs do Git
â”œâ”€â”€ .gitignore              # Arquivos ignorados pelo Git
â”œâ”€â”€ Pipfile                 # DependÃªncias do projeto
â”œâ”€â”€ Pipfile.lock            # Lock das dependÃªncias
â”œâ”€â”€ requirements.txt        # DependÃªncias (alternativa ao Pipfile)
â”œâ”€â”€ ruff.toml              # ConfiguraÃ§Ã£o do Ruff
â””â”€â”€ README.md              # Este arquivo
```

## ğŸš€ Como Usar

### Executar o Web Scraping

1. Execute o script de scraping:

```bash
cd backend/src
python scrape_languages.py
```

2. Os dados serÃ£o salvos em `backend/src/data/linguagens_programacao_tabela.csv`

## ğŸ“Š Resultados

O projeto atualmente extrai informaÃ§Ãµes de **270+ linguagens de programaÃ§Ã£o**, incluindo:

- Linguagens clÃ¡ssicas (C, Pascal, FORTRAN)
- Linguagens modernas (Python, JavaScript, Rust)
- Linguagens especializadas (SQL, MATLAB, R)
- Linguagens esotÃ©ricas (Brainfuck, Whitespace)

Os dados sÃ£o organizados em formato CSV para fÃ¡cil anÃ¡lise e visualizaÃ§Ã£o.



## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.
